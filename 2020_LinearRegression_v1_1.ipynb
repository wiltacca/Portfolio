{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wiltacca/Portfolio/blob/main/2020_LinearRegression_v1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjPbwvaTPPun"
      },
      "source": [
        "\n",
        "# Practical: Linear Regression\n",
        "\n",
        "\n",
        "\n",
        "## Objectives\n",
        "\n",
        "- Learn how use scatter plot to visualize relationship between two variables.\n",
        "- Use matplotlib to draw a best-fit line.\n",
        "- Using Scikit-Learn to generate a Linear Regression model and perform prediction.\n",
        "- Evaluate the model by looking at the sum of squares error (SSE) value, R2 and adjusted R2 values.\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The linear regression is one of the most common algorithms used to model the relationship among vaiables. It is routinely used to predict a numerical outcome from a related set of input predictors.\n",
        "\n",
        "The simplest form of linear regression involves two variables where one variable is used to predict another. The assumption is that the two variables have a linear relationship. This can be expressed as an equation below, where we wish to predict y given a known value of x.\n",
        "\n",
        "$$y = β_0+β_1x$$\n",
        "\n",
        "In the equation, the values of $β_0$ and $β_1$ is fixed and modelling  refers to the processing of determining the values of $β_0$ and $β_1$.\n",
        "\n",
        "Theorectically, for a linear relationship (straight line in a cartesian plane), we will only need 2 sets of (x, y) values (2 points) but in practise, due to noise and errors, we will usually need more. The usefulness of the equation depends on how well the values of $β_0$ and $β_1$ are chosen. That is of course possible only if we have sufficient and quality data from which to derive the best $β$ values. \n",
        "\n",
        "## Simple Linear Regression\n",
        "\n",
        "In this practical, we will see how to use data to generate a linear regression models and then use the model for prediction. We will use a simple set of data for illustration purposes.\n",
        "\n",
        "### Step 1\n",
        "\n",
        "Obtain a copy of _SimpleLinearRegressionData.csv_ file and place it in the same folder as this notebook file.\n",
        "\n",
        "We will first take a brief look at the data contained in file.\n",
        "\n",
        "### Step 2\n",
        "\n",
        "Create a new notebook in Jupyter and enter the following codes. To view some samples of the data, run the codes to display the first 5 rows of the data:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"SimpleLinearRegressionData.csv\", index_col=\"Year\")\n",
        "print(df.head())\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ikuBhR-4PWSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3-W8mJnPPuv"
      },
      "outputs": [],
      "source": [
        "#Enter your codes here to read in the SimpleLinearRegressionData.csv file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg8Mv3dbPPuy"
      },
      "source": [
        "The codes uses the ```read_csv()``` function to read data stored in a CSV file. It uses the ```Year``` column as the index column. The data is stored in a Pandas ```DataFrame``` named ```df```.\n",
        "\n",
        "The print statement will print out the first few rows of data. You should be able to see the following:\n",
        "\n",
        "![Step2.png](attachment:Step2.png)\n",
        "\n",
        "As can be seen, the data consists of the the columns *Year* (now set as the index of the ```DataFrame```), *Rates* and *Mortage*.\n",
        "Usually, it is useful to visualize the relationship between two variables using a scatter plot.\n",
        "\n",
        "### Step 3\n",
        "\n",
        "Use a scatter plot as shown in the codes below:\n",
        "\n",
        "```python\n",
        "df.plot.scatter(title=\"Plot of Rates vs Mortgages\", x=\"Rates\", y=\"Mortgage\", color=\"red\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7e_58v3PPuz"
      },
      "outputs": [],
      "source": [
        "#Enter codes to visualize the data using a scatterplot\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcG9WOmdPPu1"
      },
      "source": [
        "### Step 4\n",
        "Run the codes and you should see a scatter plot as shown below:\n",
        "\n",
        "![Step4.png](attachment:Step4.png)\n",
        "\n",
        "As can be seen from the figure, the two variables _Rates_ and _Mortgages_ are somewhat related to each other in a linear but inversely proportional manner. This implies that we should be able to get a good linear regression model.\n",
        "\n",
        "### Best-Fit Line\n",
        "Linear regression works by deriving a mathematical equation from the data. Due to inaccuracy and noise in the data, a perfect line is near impossible. Our aim is to plot a line that best fit the set of data. The best-fit line is a line that minimizes residual errors. Residual error is the difference between the observed and the predicted values.\n",
        "\n",
        "### Step 5\n",
        "\n",
        "To plot the best-fit line, insert the following codes:\n",
        "```python\n",
        "#Use Pandas to create a scatter plot, x-axis is Rates and y-axis is Mortage\n",
        "#Use red colour for the points\n",
        "ax = df.plot.scatter(x=\"Rates\", y=\"Mortgage\", color=\"red\")\n",
        "\n",
        "#polyfit = Fit the data using the least square polynomial\n",
        "#Returns a list of the coefficients\n",
        "coefficients = np.polyfit(df[\"Rates\"], df[\"Mortgage\"], 1)\n",
        "#Use the coefficients to create a polynomial\n",
        "p = np.poly1d(coefficients)\n",
        "#Evaluate the polynomial on the rates data\n",
        "df[\"best_fit\"] = p(df.loc[:, \"Rates\"])\n",
        "#Create another dataframe with rates as the index\n",
        "# and Mortage vs the best_fit points\n",
        "df2 = df.set_index(\"Rates\", inplace=False)\n",
        "#Plot\n",
        "df2.best_fit.plot(ax=ax)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH8RUF8cPPu2"
      },
      "outputs": [],
      "source": [
        "#Enter code to plot the best-fit line here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehLp3aGSPPu6"
      },
      "source": [
        "The Numpy’s ```polyfit()``` function (https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.polyfit.html) generates the coefficients of the best-fit line in the form of a vector. The coefficients are then passed into the ```poly1d()``` function to create the best-fit line. We can then plot the line using the rates column (```df.loc[:, \"Rates\"]```). The results are then plotted.\n",
        "\n",
        "Run the codes, you should see the best fit line drawn as shown in the figure below:\n",
        "\n",
        "![Step5.png](attachment:Step5.png)\n",
        "\n",
        "### Simple Linear Regression Modelling\n",
        "\n",
        "We will now generate a scikit-learn linear regression model and subsequently use the model to predict a value. The Linear Regression algorithm is found under the ```sklearn.linear_model``` module.\n",
        "\n",
        "### Step 6\n",
        "\n",
        "Create a LinearRegression model and train the model using data from the _Rates_ and _Mortage_ columns as follows:\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "#Get the rate column and reshape it to a series\n",
        "rates = df[\"Rates\"].values.reshape(-1, 1)\n",
        "#Get the mortgage column and reshape it to a series\n",
        "mortgage = df[\"Mortgage\"].values.reshape(-1, 1)\n",
        "#Create LinearRegression\n",
        "model = LinearRegression()\n",
        "#train the model using the fit() function\n",
        "model.fit(rates, mortgage)\n",
        "```\n",
        "\n",
        "Note\n",
        "```df[\"Rates\"].values``` is one data point of many features while ```df[\"Rates\"].values.reshape(-1,1)``` is many data points, each with only one feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqJnCL-6PPu9"
      },
      "outputs": [],
      "source": [
        "#Enter your codes here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVzVj6NcPPu_"
      },
      "source": [
        "We can also take a look at the equation generated by the ```fit()``` function. The coefficient ($β_1$) and intercept ($β_0$) can be retrieved using ```model.coef_``` and ```model.intercept_```.\n",
        "\n",
        "### Step 7\n",
        "\n",
        "Print out the equation of the regression model as follows:\n",
        "\n",
        "```python\n",
        "print(\"Equation y={0:.2f}*x + {1:.2f}\".format(model.coef_[0][0], model.intercept_[0]))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpuR8hIkPPvD"
      },
      "outputs": [],
      "source": [
        "#Print our the model coefficients and intercept there\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW90qNIqPPvE"
      },
      "source": [
        "You should see the following results:\n",
        "\n",
        "```\n",
        "Equation y=-32518.17*x + 501105.72\n",
        "```\n",
        "\n",
        "This is the mathematical model that can be used for subsequent prediction using the ```predict()``` function.\n",
        "To see how prediction works, we will input a value of 8.0 for the rates and see how well the model works. Based on the best-fit line we plotted earlier, we can guess that the predicted valued will be between 225k and 250k.\n",
        "\n",
        "### Step 8\n",
        "\n",
        "Key in the following codes and execute them to see the results for predicting mortage at a rate of 8%\n",
        "\n",
        "```python\n",
        "#Create a test value for rate of 8.0\n",
        "test_rate = np.array([[8.0]])\n",
        "#Use the predict function of the model to perform the prediction\n",
        "predicted_mortgage = model.predict(test_rate)[0][0]\n",
        "#Print out the predicted mortgage value\n",
        "print(\"Predicted mortgage: {0:.2f}\".format(predicted_mortgage))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fq-4lNhPPvF"
      },
      "outputs": [],
      "source": [
        "#Enter codes to perform prediction using your Regression model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjVCSjqbPPvH"
      },
      "source": [
        "You should see the following output:\n",
        "\n",
        "```\n",
        "Predicted mortgage: 240960.40\n",
        "```\n",
        "\n",
        "As can be seen from the best-fit line, the value is approximately 240k which is inline with the prediction. You can also verify the value by substituting the value in the equation generated previously.\n",
        "\n",
        "### Evaluating the Model\n",
        "\n",
        "Very often, we will need to know how well our model works, especially when we need to compare different models and pick the best among them.\n",
        "\n",
        "### Sum of Squares Error (SSE)\n",
        "\n",
        "The Sum of Squares Error (SSE) value provides an indication of the performance of a model. Recall that we generate a model by minimizing the SSE of the training data, in other words, the lower the value of SSE, the small the prediction error.\n",
        "\n",
        "### Step 9\n",
        "\n",
        "To generate the SSE value of our model, we can do the following:\n",
        "\n",
        "```python\n",
        "#Calculates the SSE value\n",
        "rss = np.mean((model.predict(rates)- mortgage)**2)\n",
        "#Print out the SSE value\n",
        "print(\"SSE: {0:.2f}\".format(rss))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZmSdXlbPPvI"
      },
      "outputs": [],
      "source": [
        "#Enter codes to calculate the RSS value of your model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "oCrG6kDUPPvI"
      },
      "source": [
        "The line of codes use the model object to perform predictions and calculate the square of the difference between the actual and predicted values. The mean value is then calculated and printed.\n",
        "\n",
        "### Step 10\n",
        "\n",
        "Run the codes and you should see the following results:\n",
        "\n",
        "```\n",
        "SSE: 386904189.98\n",
        "```\n",
        "\n",
        "In situation that more and better-quality data are available, you can re-generate the model and obtain better (smaller) SSE value.\n",
        "\n",
        "### Coefficient of Determination ($R^2$) Value\n",
        "\n",
        "$R^2$ value is an important and commonly used value to compare the predictive power of the models. ```Scikit-Learn``` package provides a ```r2_score()``` function under ```sklearn.metrics``` that can helps to calculate the $R^2$ value.\n",
        "\n",
        "### Step 11\n",
        "\n",
        "Add the ```Import``` statement to import the ```r2_score()``` function from ```sklearn.metrics``` module as follows:\n",
        "\n",
        "```python\n",
        "#import the r2_score function\n",
        "from sklearn.metrics import r2_score\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP_xKfZDPPvJ"
      },
      "outputs": [],
      "source": [
        "#Import the r2_score function\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf343lAEPPvJ"
      },
      "source": [
        "### Step 12\n",
        "\n",
        "Use the following codes to generate the $R^2$ value of our model:\n",
        "\n",
        "```python\n",
        "#Calculates the R sequared value\n",
        "r2 = r2_score(mortgage, model.predict(rates))\n",
        "#Print out the R sequared value\n",
        "print(\"R Squared: {0:.2f}\".format(r2))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71z2qHHUPPvJ"
      },
      "outputs": [],
      "source": [
        "#Enter your codes to print out the R2 score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R-wVmWmPPvK"
      },
      "source": [
        "The ```r2_score()``` function accepts two parameters - an array of true values and the predicted values. It will calculate the $R^2$ value for us.\n",
        "\n",
        "### Step 13\n",
        "\n",
        "Run the codes and you should see the following results:\n",
        "\n",
        "```R Squared: 0.82```\n",
        "\n",
        "Values of $R^2$ ranges from 0 (worst) to 1 (best). A score of 0.82 is very good performance for our model. This is not unexpected as the scatter plot already shown us that the variables are linearly related."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCJU5W0jPPvK"
      },
      "source": [
        "## Exercise: Multiple Linear Regression\n",
        "\n",
        "In most real-world problems, we will need to deal with more than one input variables. In such cases, we can use a more generalized equation:\n",
        "\n",
        "$$y=β_0+β_1 x_1+β_2 x_2+⋯+β_kx_k$$\n",
        "Where $k$ is the number of input variables/predictors.\n",
        "\n",
        "Let us now extend the use of scikit-learn regression model from single to three input variables. We will be using a dataset containing insurance claims for a single medical treatment performed in a hospital. In addition to the claim amount (CLAIM), the data file also contains patient age (AGE), length of hospital stay (LOS) and a severity of illness category (ASG). The ASG field is based on several health measures and higher scores indicate greater severity of the illness. \n",
        "\n",
        "In this exercise, you are required to build a regression model that predicts the total claim amount for a patient based on his/her length of stay, severity of illness and patient age.\n",
        "Use the codes you have done in the previous section and the following task list as a guide:\n",
        "\n",
        "[The full answer is provided below]\n",
        "1. Obtain a copy of InsuranceClaim.csv file and place it in the same directory as your source codes. \n",
        "2. Read in the values using numpy or pandas.\n",
        "\n",
        "If you use Numpy, you can use the ```genfromtxt()``` function to read in values. Also, remember to remove the heading.\n",
        "\n",
        "3.\tCreate a LinearRegression model.\n",
        "4.\tTrain the model using the fit() function.\n",
        "5.\tUse the model to predict and print out a predicted claim value.\n",
        "6.\tPrint out the regression equation.\n",
        "7.\tPrint out R2 value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "137EVFLrPPvK"
      },
      "outputs": [],
      "source": [
        "#Enter your answers here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "raw_mimetype": "text/html",
        "tags": [
          "hidecode"
        ],
        "id": "Rw3DMhYSPPvL"
      },
      "source": [
        "The following shows the answer using Numpy or Pandas.\n",
        "\n",
        "#### Numpy\n",
        "\n",
        "<details>\n",
        "    <summary>Click here for answer in Numpy</summary>\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#Read in the CSV file using Numpy, indicating values are separated using , character\n",
        "data = np.genfromtxt(\"InsuranceClaim.csv\", delimiter=\",\")\n",
        "data = data[1:, :] #Remove heading in first row\n",
        "\n",
        "#Initialize Linear Regression model\n",
        "model = LinearRegression()\n",
        "#Train the model with our input variables and labelled data\n",
        "model.fit(data[:, :3], data[:, 3])\n",
        "\n",
        "#A sample of testing data\n",
        "test_data = np.array([\n",
        "    [0, 26, 2]\n",
        "])\n",
        "\n",
        "#Results of using the model to predict\n",
        "print(\"Predicted claim is: {0:.2f} \".format(model.predict(test_data)[0]))\n",
        "coeff = model.coef_\n",
        "print(\"Equation: {0:.2f} * ASG + {1:.2f} * AGE + {2:.2f} * LOS + {3:.2f}\".format(coeff[0], coeff[1], coeff[2], model.intercept_))\n",
        "print(\"R Squared: {0:.2f}\".format(r2_score(data[:, 3], model.predict(data[:, :3]))))\n",
        "```\n",
        "    \n",
        "    \n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### Pandas\n",
        "<details>\n",
        "    <summary>Click here for answer in Pandas</summary>\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "df = pd.read_csv(\"InsuranceClaim.csv\")\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(df.iloc[:, :3], df.iloc[:, 3])\n",
        "\n",
        "test_data = np.array([\n",
        "    [0, 26, 2]\n",
        "])\n",
        "\n",
        "print(\"Predicted claim is: {0:.2f} \".format(model.predict(test_data)[0]))\n",
        "coeff = model.coef_\n",
        "print(\"Equation: {0:.2f} * ASG + {1:.2f} * AGE + {2:.2f} * LOS + {3:.2f}\".format(coeff[0], coeff[1], coeff[2], model.intercept_))\n",
        "print(\"R Squared: {0:.2f}\".format(r2_score(df.iloc[:, 3], model.predict(df.iloc[:, :3]))))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLXou5laPPvL"
      },
      "source": [
        "### Step 13 \n",
        "\n",
        "#### Adjusted R2\n",
        "In some cases, $R^2$ does not provide the best evaluation measurement of the performance of our model. This is because $R^2$ measurement does not penalize the inclusion of useless input variables. In other words, the more input variables used in the model, the higher the score. This is not desireable as including input variables that does not contributes significantly to quality of the prediction adds costs for data collection as well as processing time. \n",
        "It is thus useful to use Adjusted $R^2$ defined as:\n",
        "\n",
        "$$Adjusted\\, R^2 = 1 - \\frac{(1-R^2)(n-1)}{n-p-1}$$\n",
        "\n",
        "Where $n$ = number of data samples in the data and $p$ = number of input variables\n",
        "As can be seen from the equation, as p increases, adjusted $R^2$ value decreases (the larger the value of $R^2$, the better the model).\n",
        "The following codes calculates the adjusted $R^2$ value from the $R^2$ we obtained previously from the ```r2_score()``` function.\n",
        "\n",
        "#### Numpy\n",
        "\n",
        "```python\n",
        "r2 = r2_score(data[:, 3], model.predict(data[:, :3]))\n",
        "number_variables = data.shape[1] -1 #-1 because data set includes the labelled data\n",
        "adjusted_r2 = 1 - ((1-r2) * (data.shape[0]-1)) / (data.shape[0]-number_variables-1)\n",
        "print(\"Adjusted R Squared: {0:.2f}\".format(adjusted_r2))\n",
        "```\n",
        "\n",
        "#### Pandas\n",
        "```python\n",
        "r2 = r2_score(df.iloc[:, 3], model.predict(df.iloc[:, :3]))\n",
        "number_variables = df.shape[1]-1\n",
        "adjusted_r2 = 1 - ((1-r2) * (df.shape[0]-1)) / (df.shape[0]-df.shape[1]-1)\n",
        "print(\"Adjusted R Squared: {0:.2f}\".format(adjusted_r2))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk5_SGEsPPvM"
      },
      "outputs": [],
      "source": [
        "# Try it out, enter your codes here to calculate the Adjusted R2 value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbow6xwJPPvM"
      },
      "source": [
        "If you run the codes, you should see that $R^2$ value is 0.32 while adjusted $R^2$ value is 0.31, showing that adjusted $R^2$ value is less as it takes into account the number of input variables used. Note also that $R^2$ and adjusted $R^2$ values will be very similar if the number of data samples is much larger then the number of input variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVwE806oPPvM"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "In the practical, we looked at how to use create a polymomial that fits a set of data using the least square method. The polynomial is then displayed as the best-fit line.\n",
        "\n",
        "We also see how to use Scikit-Learn to generate Linear and Regression models (both for simple and mulitple variables).  We have also seen how to evaluate the models using the SSE, R squared and adjusted R squared values."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "2020 LinearRegression v1.1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}